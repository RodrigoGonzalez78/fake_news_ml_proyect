{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b3b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c30b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.read_csv('../data/processed/data_limpio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34975858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original: 60994\n",
      "Training set (60%):   36596\n",
      "Validation set (20%): 12199\n",
      "Test set (20%):       12199\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que X e y son tus datos completos (combined_text y label)\n",
    "X = df_final['combined_text'].values\n",
    "y = df_final['label'].values\n",
    "\n",
    "# PASO 1: Separar el TEST definitivo (digamos, 20%)\n",
    "# X_temp contiene el 80% restante (que será Train + Val)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PASO 2: Separar TRAIN y VALIDATION de ese X_temp\n",
    "# Queremos que Val sea mas o menos el 20% del total original.\n",
    "# Si X_temp es el 80% del total, sacar el 25% de X_temp nos da el 20% del total (0.8 * 0.25 = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Total original: {len(X)}\")\n",
    "print(f\"Training set (60%):   {len(X_train)}\")\n",
    "print(f\"Validation set (20%): {len(X_val)}\")\n",
    "print(f\"Test set (20%):       {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94428ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "VOCAB_SIZE = 10000 # Tamaño del vocabulario\n",
    "MAX_LENGTH = 250 # Longitud máxima de las secuencias\n",
    "OOV_TOK = \"<OOV>\" # Token para palabras fuera del vocabulario\n",
    "\n",
    "# 1. Tokenizer (SOLO con Train)\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOK)\n",
    "tokenizer.fit_on_texts(X_train) \n",
    "\n",
    "# 2. Convertir a secuencias\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)   # Usamos el tokenizer ya entrenado\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test) # Usamos el tokenizer ya entrenado\n",
    "\n",
    "# 3. Padding\n",
    "X_train_padded = pad_sequences(train_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "X_val_padded = pad_sequences(val_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(test_sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Convertir a numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "640a9550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrick/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-12-13 00:39:00.511498: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimensión de los vectores de embedding (16, 32, 64 son comunes)\n",
    "EMBEDDING_DIM = 16 \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Capa 1: Embedding (Aprende relaciones entre palabras)\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
    "    \n",
    "    # Capa 2: LSTM (Bidireccional es mejor porque lee izquierda-derecha y viceversa)\n",
    "    # Dropout ayuda a evitar el Overfitting (memorización)\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "    \n",
    "    # Capa 3: Densa para procesar lo aprendido\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    \n",
    "    # Capa 4: Dropout extra de seguridad\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Capa de Salida: 1 sola neurona con Sigmoid (porque la salida es 0 o 1)\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilación\n",
    "model.compile(loss='binary_crossentropy', # Función de pérdida para clasificación binaria\n",
    "              optimizer='adam',           # El mejor optimizador general\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b816355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1144/1144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 91ms/step - accuracy: 0.8645 - loss: 0.2976 - val_accuracy: 0.9598 - val_loss: 0.1120\n",
      "Epoch 2/5\n",
      "\u001b[1m1144/1144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9714 - loss: 0.0888 - val_accuracy: 0.9660 - val_loss: 0.1003\n",
      "Epoch 3/5\n",
      "\u001b[1m1144/1144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 88ms/step - accuracy: 0.9819 - loss: 0.0570 - val_accuracy: 0.9622 - val_loss: 0.1140\n",
      "Epoch 4/5\n",
      "\u001b[1m1144/1144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 86ms/step - accuracy: 0.9921 - loss: 0.0302 - val_accuracy: 0.9628 - val_loss: 0.1258\n",
      "Epoch 5/5\n",
      "\u001b[1m1144/1144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 87ms/step - accuracy: 0.9942 - loss: 0.0210 - val_accuracy: 0.9650 - val_loss: 0.1711\n",
      "\n",
      "--- Evaluación Final en Test Set ---\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9649 - loss: 0.1587\n",
      "Precisión Real del Modelo: 96.40%\n"
     ]
    }
   ],
   "source": [
    "# Asumiendo que ya definiste el modelo 'model' como hicimos antes...\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_padded, y_train, \n",
    "    epochs=5,\n",
    "    # AQUI está la clave: usamos validation_data con el set de validación\n",
    "    validation_data=(X_val_padded, y_val), \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- EVALUACIÓN FINAL ---\n",
    "# Solo ahora, al final de todo, miramos el Test Set\n",
    "print(\"\\n--- Evaluación Final en Test Set ---\")\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f\"Precisión Real del Modelo: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb6cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'detector_fake_news.keras'\n",
      "Tokenizer guardado como 'tokenizer.pickle'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 1. Guardar el Modelo (formato nativo de Keras)\n",
    "model.save('detector_fake_news.keras')\n",
    "print(\"Modelo guardado como 'detector_fake_news.keras'\")\n",
    "\n",
    "# 2. Guardar el Tokenizer (usando Pickle)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tokenizer guardado como 'tokenizer.pickle'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
